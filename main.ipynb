{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features exploration\n",
    "\n",
    "All features given are numerical (including but not limited to boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
       "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n",
       "       'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "trainDf = pd.read_csv('train.csv')\n",
    "trainDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data (Not including boolean)\n",
    "\n",
    "- BMI\n",
    "- GenHlth\n",
    "- MentHlth\n",
    "- PhysHlth\n",
    "- Age\n",
    "- Education\n",
    "- Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>29.447441</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>2.702102</td>\n",
       "      <td>3.617017</td>\n",
       "      <td>5.195954</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>8.376041</td>\n",
       "      <td>4.958548</td>\n",
       "      <td>5.852836</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>7.080019</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>1.106379</td>\n",
       "      <td>7.997166</td>\n",
       "      <td>9.538762</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>2.920253</td>\n",
       "      <td>1.018217</td>\n",
       "      <td>2.131317</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck          BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035    29.447441     0.473225   \n",
       "std       0.499857     0.500009     0.164889     7.080019     0.499332   \n",
       "min       0.000000     0.000000     0.000000    14.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000    25.000000     0.000000   \n",
       "50%       1.000000     0.000000     1.000000    28.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000    33.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000    98.000000     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     2.702102     3.617017     5.195954   \n",
       "std       0.398785  ...     0.280213     1.106379     7.997166     9.538762   \n",
       "min       0.000000  ...     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     2.000000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     3.000000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     3.000000     2.000000     5.000000   \n",
       "max       1.000000  ...     1.000000     5.000000    30.000000    30.000000   \n",
       "\n",
       "          DiffWalk          Sex          Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441     8.376041     4.958548     5.852836   \n",
       "std       0.405240     0.497279     2.920253     1.018217     2.131317   \n",
       "min       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "25%       0.000000     0.000000     7.000000     4.000000     4.000000   \n",
       "50%       0.000000     0.000000     9.000000     5.000000     6.000000   \n",
       "75%       0.000000     1.000000    10.000000     6.000000     8.000000   \n",
       "max       1.000000     1.000000    13.000000     6.000000     8.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 7\n",
      "Number of boolean features: 14\n"
     ]
    }
   ],
   "source": [
    "CONTINUOUS_FEATURES = [\"BMI\", \"Age\"]\n",
    "ORDINAL_FEATURES = [\"GenHlth\", \"MentHlth\", \"PhysHlth\", \"Education\", \"Income\"]\n",
    "\n",
    "BOOLEAN_FEATURES = [\n",
    "    col\n",
    "    for col in trainDf.columns\n",
    "    if col not in CONTINUOUS_FEATURES\n",
    "    and col not in ORDINAL_FEATURES\n",
    "    and col != \"output\"\n",
    "]\n",
    "\n",
    "print(f\"Number of numerical features: {len(CONTINUOUS_FEATURES) + len(ORDINAL_FEATURES)}\")\n",
    "print(f\"Number of boolean features: {len(BOOLEAN_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "Check outliner of BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class Outliner:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df: DataFrame):\n",
    "        self.Q1 = df.quantile(0.25)\n",
    "        self.Q3 = df.quantile(0.75)\n",
    "        self.IQR = self.Q3 - self.Q1\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        df[((df < (self.Q1 - 1.5 * self.IQR)) | (df > (self.Q3 + 1.5 * self.IQR)))] = (\n",
    "            np.nan\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>-2.113872e-16</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.425526</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.173198</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>-5.214217e-17</td>\n",
       "      <td>0.791710</td>\n",
       "      <td>0.693262</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>0.276595</td>\n",
       "      <td>0.266572</td>\n",
       "      <td>0.317959</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.203643</td>\n",
       "      <td>0.304474</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.182052e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.526073e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.282303e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.712529e-01</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.044606e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136872e-01</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.018222e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.561573e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.683498e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.583567e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck           BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5.042000e+03  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035 -2.113872e-16     0.473225   \n",
       "std       0.499857     0.500009     0.164889  1.000099e+00     0.499332   \n",
       "min       0.000000     0.000000     0.000000 -2.182052e+00     0.000000   \n",
       "25%       0.000000     0.000000     1.000000 -6.282303e-01     0.000000   \n",
       "50%       1.000000     0.000000     1.000000 -2.044606e-01     0.000000   \n",
       "75%       1.000000     1.000000     1.000000  5.018222e-01     1.000000   \n",
       "max       1.000000     1.000000     1.000000  9.683498e+00     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     0.425526     0.120567     0.173198   \n",
       "std       0.398785  ...     0.280213     0.276595     0.266572     0.317959   \n",
       "min       0.000000  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     0.250000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     0.500000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     0.500000     0.066667     0.166667   \n",
       "max       1.000000  ...     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          DiffWalk          Sex           Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5.042000e+03  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441 -5.214217e-17     0.791710     0.693262   \n",
       "std       0.405240     0.497279  1.000099e+00     0.203643     0.304474   \n",
       "min       0.000000     0.000000 -2.526073e+00     0.000000     0.000000   \n",
       "25%       0.000000     0.000000 -4.712529e-01     0.600000     0.428571   \n",
       "50%       0.000000     0.000000  2.136872e-01     0.800000     0.714286   \n",
       "75%       0.000000     1.000000  5.561573e-01     1.000000     1.000000   \n",
       "max       1.000000     1.000000  1.583567e+00     1.000000     1.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "trainDf[CONTINUOUS_FEATURES] = stdScaler.fit_transform(trainDf[CONTINUOUS_FEATURES])\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "trainDf[ORDINAL_FEATURES] = minMaxScaler.fit_transform(trainDf[ORDINAL_FEATURES])\n",
    "\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammatical Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape\n",
      "/home/tu/code-py/evolutionary-computation/mid-project\n"
     ]
    }
   ],
   "source": [
    "# switch directory to use grape\n",
    "%cd ../grape\n",
    "\n",
    "# import grape and necessary functions\n",
    "import grape\n",
    "from algorithms import ge_eaSimpleWithElitism\n",
    "from functions import pdiv\n",
    "\n",
    "\n",
    "# switch back to the original directory\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "\n",
    "RANDOM_SEED = 17\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "POPULATION_SIZE = 1000\n",
    "MAX_GENERATIONS = 100\n",
    "P_CROSSOVER = 0.8\n",
    "P_MUTATION = 0.05\n",
    "HALLOFFAME_SIZE = max(round(0.01 * POPULATION_SIZE), 1)  # it should be at least 1\n",
    "ELITE_SIZE = min(round(0.01 * POPULATION_SIZE), HALLOFFAME_SIZE)\n",
    "\n",
    "CODON_CONSUMPTION = \"lazy\"\n",
    "GENOME_REPRESENTATION = \"list\"\n",
    "MAX_GENOME_LENGTH = None\n",
    "\n",
    "MAX_INIT_TREE_DEPTH = 13\n",
    "MIN_INIT_TREE_DEPTH = 3\n",
    "MAX_TREE_DEPTH = 90\n",
    "MAX_WRAPS = 0\n",
    "CODON_SIZE = 255\n",
    "\n",
    "REPORT_ITEMS = [\n",
    "    \"gen\",\n",
    "    \"invalid\",\n",
    "    \"avg\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"fitness_test\",\n",
    "    \"best_ind_length\",\n",
    "    \"avg_length\",\n",
    "    \"best_ind_nodes\",\n",
    "    \"avg_nodes\",\n",
    "    \"best_ind_depth\",\n",
    "    \"avg_depth\",\n",
    "    \"avg_used_codons\",\n",
    "    \"best_ind_used_codons\",\n",
    "    \"selection_time\",\n",
    "    \"generation_time\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['<compare_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['and_(<logic_op>, <logic_op>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['or_(<logic_op>, <logic_op>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['not_(<logic_op>)', 'non-terminal', 1, 3, True, 3],\n",
       "  ['<bool_feat>', 'non-terminal', 1, 4, False, 2]],\n",
       " [['greater_than(<number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   2,\n",
       "   0,\n",
       "   True,\n",
       "   3],\n",
       "  ['less_than(<number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   2,\n",
       "   1,\n",
       "   True,\n",
       "   3]],\n",
       " [['<number_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['<number_feat>', 'non-terminal', 1, 1, False, 2],\n",
       "  ['<number>', 'non-terminal', 1, 2, False, 3]],\n",
       " [['add(<number_value>, <number_value>)', 'non-terminal', 2, 0, True, 3],\n",
       "  ['sub(<number_value>, <number_value>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['mul(<number_value>, <number_value>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['div(<number_value>, <number_value>)', 'non-terminal', 2, 3, True, 3]],\n",
       " [['<d>.<d><d><d><d>', 'non-terminal', 5, 0, False, 2],\n",
       "  ['-<d>.<d><d><d><d>', 'non-terminal', 5, 1, False, 2]],\n",
       " [['0', 'terminal', 0, 0, False, 1],\n",
       "  ['1', 'terminal', 0, 1, False, 1],\n",
       "  ['2', 'terminal', 0, 2, False, 1],\n",
       "  ['3', 'terminal', 0, 3, False, 1],\n",
       "  ['4', 'terminal', 0, 4, False, 1],\n",
       "  ['5', 'terminal', 0, 5, False, 1],\n",
       "  ['6', 'terminal', 0, 6, False, 1],\n",
       "  ['7', 'terminal', 0, 7, False, 1],\n",
       "  ['8', 'terminal', 0, 8, False, 1],\n",
       "  ['9', 'terminal', 0, 9, False, 1]],\n",
       " [['nf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['nf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['nf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['nf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['nf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['nf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['nf[6]', 'terminal', 0, 6, False, 1]],\n",
       " [['bf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['bf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['bf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['bf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['bf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['bf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['bf[6]', 'terminal', 0, 6, False, 1],\n",
       "  ['bf[7]', 'terminal', 0, 7, False, 1],\n",
       "  ['bf[8]', 'terminal', 0, 8, False, 1],\n",
       "  ['bf[9]', 'terminal', 0, 9, False, 1],\n",
       "  ['bf[10]', 'terminal', 0, 10, False, 1],\n",
       "  ['bf[11]', 'terminal', 0, 11, False, 1],\n",
       "  ['bf[12]', 'terminal', 0, 12, False, 1],\n",
       "  ['bf[13]', 'terminal', 0, 13, False, 1]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = grape.Grammar(\"./gramma.bnf\")\n",
    "grammar.production_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def and_(a, b):\n",
    "    return np.logical_and(a, b)\n",
    "def or_(a, b):\n",
    "    return np.logical_or(a, b)\n",
    "def not_(a):\n",
    "    return np.logical_not(a)\n",
    "\n",
    "def greater_than(a, b):\n",
    "    return (a > b)\n",
    "def less_than(a, b):\n",
    "    return (a < b)\n",
    "\n",
    "def add(a, b):\n",
    "    return (a + b)\n",
    "def sub(a, b):\n",
    "    return (a - b)\n",
    "def mul(a, b):\n",
    "    return (a * b)\n",
    "def div(a, b):\n",
    "    return pdiv(a, b)\n",
    "\n",
    "\n",
    "class GE_ExecuteError(Exception):\n",
    "    # take a message as input\n",
    "    def __init__(self, message=\"Error during the execution of the individual\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "    pass\n",
    "\n",
    "def gePredict(individual, nf, bf):\n",
    "    \"\"\"Predict if a case is positive or negative using ge and the individual.\n",
    "\n",
    "    Args:\n",
    "        individual (_type_): a valid GE individual\n",
    "        nf (_type_): numerical features\n",
    "        bf (_type_): boolean features\n",
    "\n",
    "    Raises:\n",
    "        GE_ExecuteError: if error happens during the execution of the individual\n",
    "\n",
    "    Returns:\n",
    "        int: 0 if the case is negative, 1 if the case is positive\n",
    "    \"\"\"\n",
    "    \n",
    "    nf = np.array(nf)\n",
    "    bf = np.array(bf)\n",
    "    \n",
    "    assert nf.ndim == bf.ndim, \"Numerical and Boolean data must have the same number of dimensions\"\n",
    "    \n",
    "    # execute\n",
    "    try:\n",
    "        if nf.ndim == 1:\n",
    "            res = eval(individual.phenotype)\n",
    "            pred = 1 if res > 0 else 0\n",
    "            return pred\n",
    "        \n",
    "        if nf.ndim == 2:\n",
    "            assert nf.shape[0] == bf.shape[0], \"Numerical and Boolean data must have the same number of samples\"\n",
    "            \n",
    "            nf = nf.T\n",
    "            bf = bf.T\n",
    "        \n",
    "            res = eval(individual.phenotype)\n",
    "            pred = [1 if res[i] > 0 else 0 for i in range(len(res))]\n",
    "            return pred\n",
    "        \n",
    "        raise NotImplementedError(\"Data with more than 2 dimensions is not supported\")\n",
    "        \n",
    "    except (\n",
    "        FloatingPointError,\n",
    "        ZeroDivisionError,\n",
    "        OverflowError,\n",
    "        MemoryError,\n",
    "        IndexError,\n",
    "        TypeError,\n",
    "    ) as e:\n",
    "        raise GE_ExecuteError(str(e))\n",
    "\n",
    "def fitness(individual, points):\n",
    "    if individual.invalid:\n",
    "        return np.nan,\n",
    "    \n",
    "    x, Y = points\n",
    "    \n",
    "    nf = x[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "    bf = x[BOOLEAN_FEATURES].to_numpy()\n",
    "    \n",
    "    try:\n",
    "        pred = gePredict(individual, nf, bf)\n",
    "        \n",
    "        errRate = np.sum(np.abs(Y - pred)) / len(Y)\n",
    "    except GE_ExecuteError:\n",
    "        return np.nan,\n",
    "\n",
    "    \n",
    "    return (errRate,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# define a single objective, minimising fitness strategy:\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", grape.Individual, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox.register(\"populationCreator\", grape.sensible_initialisation, creator.Individual)\n",
    "toolbox.register(\"evaluate\", fitness)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=7)\n",
    "toolbox.register(\"mate\", grape.crossover_onepoint)\n",
    "toolbox.register(\"mutate\", grape.mutation_int_flip_per_codon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "X_train = trainDf.drop(columns=[\"output\"])\n",
    "y_train = trainDf[\"output\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:124: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid them.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid them.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 0 , Best fitness = (np.float64(0.2933359777865926),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 1 , Best fitness = (np.float64(0.2933359777865926),) , Number of invalids = 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 2 , Best fitness = (np.float64(0.2933359777865926),) , Number of invalids = 163\n",
      "gen = 3 , Best fitness = (np.float64(0.2933359777865926),) , Number of invalids = 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 4 , Best fitness = (np.float64(0.2933359777865926),) , Number of invalids = 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 5 , Best fitness = (np.float64(0.292542641808806),) , Number of invalids = 213\n",
      "gen = 6 , Best fitness = (np.float64(0.292542641808806),) , Number of invalids = 217\n",
      "gen = 7 , Best fitness = (np.float64(0.292542641808806),) , Number of invalids = 192\n",
      "gen = 8 , Best fitness = (np.float64(0.292542641808806),) , Number of invalids = 165\n",
      "gen = 9 , Best fitness = (np.float64(0.292542641808806),) , Number of invalids = 164\n",
      "gen = 10 , Best fitness = (np.float64(0.2913526378421261),) , Number of invalids = 132\n",
      "gen = 11 , Best fitness = (np.float64(0.2913526378421261),) , Number of invalids = 173\n",
      "gen = 12 , Best fitness = (np.float64(0.289170963903213),) , Number of invalids = 137\n",
      "gen = 13 , Best fitness = (np.float64(0.282427608092027),) , Number of invalids = 144\n",
      "gen = 14 , Best fitness = (np.float64(0.282427608092027),) , Number of invalids = 144\n",
      "gen = 15 , Best fitness = (np.float64(0.27945259817532725),) , Number of invalids = 156\n",
      "gen = 16 , Best fitness = (np.float64(0.27945259817532725),) , Number of invalids = 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 17 , Best fitness = (np.float64(0.2731059103530345),) , Number of invalids = 160\n",
      "gen = 18 , Best fitness = (np.float64(0.2731059103530345),) , Number of invalids = 164\n",
      "gen = 19 , Best fitness = (np.float64(0.2731059103530345),) , Number of invalids = 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 20 , Best fitness = (np.float64(0.2731059103530345),) , Number of invalids = 173\n",
      "gen = 21 , Best fitness = (np.float64(0.2731059103530345),) , Number of invalids = 163\n",
      "gen = 22 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 180\n",
      "gen = 23 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 129\n",
      "gen = 24 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 111\n",
      "gen = 25 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 119\n",
      "gen = 26 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 110\n",
      "gen = 27 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 107\n",
      "gen = 28 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 91\n",
      "gen = 29 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 30 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 98\n",
      "gen = 31 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 32 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 78\n",
      "gen = 33 , Best fitness = (np.float64(0.26715589051963506),) , Number of invalids = 81\n",
      "gen = 34 , Best fitness = (np.float64(0.2663625545418485),) , Number of invalids = 89\n",
      "gen = 35 , Best fitness = (np.float64(0.2663625545418485),) , Number of invalids = 71\n",
      "gen = 36 , Best fitness = (np.float64(0.2661642205474018),) , Number of invalids = 96\n",
      "gen = 37 , Best fitness = (np.float64(0.2661642205474018),) , Number of invalids = 76\n",
      "gen = 38 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 97\n",
      "gen = 39 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 63\n",
      "gen = 40 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 53\n",
      "gen = 41 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 45\n",
      "gen = 42 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 43\n",
      "gen = 43 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 43\n",
      "gen = 44 , Best fitness = (np.float64(0.26378421261404206),) , Number of invalids = 25\n",
      "gen = 45 , Best fitness = (np.float64(0.2635858786195954),) , Number of invalids = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 46 , Best fitness = (np.float64(0.2631892106307021),) , Number of invalids = 38\n",
      "gen = 47 , Best fitness = (np.float64(0.2631892106307021),) , Number of invalids = 30\n",
      "gen = 48 , Best fitness = (np.float64(0.2631892106307021),) , Number of invalids = 28\n",
      "gen = 49 , Best fitness = (np.float64(0.2629908766362555),) , Number of invalids = 15\n",
      "gen = 50 , Best fitness = (np.float64(0.2629908766362555),) , Number of invalids = 20\n",
      "gen = 51 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 19\n",
      "gen = 52 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 17\n",
      "gen = 53 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 27\n",
      "gen = 54 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 55 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 56 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 57 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 29\n",
      "gen = 58 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 26\n",
      "gen = 59 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 21\n",
      "gen = 60 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 61 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 23\n",
      "gen = 62 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 12\n",
      "gen = 63 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 16\n",
      "gen = 64 , Best fitness = (np.float64(0.26219754065846884),) , Number of invalids = 19\n",
      "gen = 65 , Best fitness = (np.float64(0.2619992066640222),) , Number of invalids = 13\n",
      "gen = 66 , Best fitness = (np.float64(0.2619992066640222),) , Number of invalids = 26\n",
      "gen = 67 , Best fitness = (np.float64(0.2619992066640222),) , Number of invalids = 18\n",
      "gen = 68 , Best fitness = (np.float64(0.2619992066640222),) , Number of invalids = 9\n",
      "gen = 69 , Best fitness = (np.float64(0.26140420468068226),) , Number of invalids = 15\n",
      "gen = 70 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 19\n",
      "gen = 71 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 17\n",
      "gen = 72 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 7\n",
      "gen = 73 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 18\n",
      "gen = 74 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 16\n",
      "gen = 75 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 76 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 15\n",
      "gen = 77 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 16\n",
      "gen = 78 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 11\n",
      "gen = 79 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n",
      "gen = 80 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 8\n",
      "gen = 81 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 82 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 7\n",
      "gen = 83 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 10\n",
      "gen = 84 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 12\n",
      "gen = 85 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 86 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 13\n",
      "gen = 87 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 11\n",
      "gen = 88 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 10\n",
      "gen = 89 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n",
      "gen = 90 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n",
      "gen = 91 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 8\n",
      "gen = 92 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 93 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 9\n",
      "gen = 94 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 11\n",
      "gen = 95 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 13\n",
      "gen = 96 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 14\n",
      "gen = 97 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 98 , Best fitness = (np.float64(0.2606108687028957),) , Number of invalids = 15\n",
      "gen = 99 , Best fitness = (np.float64(0.26041253470844905),) , Number of invalids = 11\n",
      "gen = 100 , Best fitness = (np.float64(0.26041253470844905),) , Number of invalids = 9\n"
     ]
    }
   ],
   "source": [
    "# population and hall of fame:\n",
    "population = toolbox.populationCreator(\n",
    "    pop_size=POPULATION_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    min_init_depth=MIN_INIT_TREE_DEPTH,\n",
    "    max_init_depth=MAX_INIT_TREE_DEPTH,\n",
    "    codon_size=CODON_SIZE,\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    ")\n",
    "hof = tools.HallOfFame(HALLOFFAME_SIZE)\n",
    "\n",
    "# prepare the statistics object:\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.nanmean)\n",
    "stats.register(\"std\", np.nanstd)\n",
    "stats.register(\"min\", np.nanmin)\n",
    "stats.register(\"max\", np.nanmax)\n",
    "\n",
    "# run the algorithm:\n",
    "population, logbook = ge_eaSimpleWithElitism(\n",
    "    population,\n",
    "    toolbox,\n",
    "    cxpb=P_CROSSOVER,\n",
    "    mutpb=P_MUTATION,\n",
    "    ngen=MAX_GENERATIONS,\n",
    "    elite_size=ELITE_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    codon_size=CODON_SIZE,\n",
    "    max_tree_depth=MAX_TREE_DEPTH,\n",
    "    max_genome_length=MAX_GENOME_LENGTH,\n",
    "    points_train=[X_train, y_train],\n",
    "    # points_test=[X_test, y_test],\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    report_items=REPORT_ITEMS,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    "    stats=stats,\n",
    "    halloffame=hof,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ee91a32af40>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "gen = logbook.select(\"gen\")\n",
    "fit_mins = logbook.select(\"min\")\n",
    "fit_avgs = logbook.select(\"avg\")\n",
    "\n",
    "plt.plot(gen, fit_mins, \"b-\", label=\"Minimum Fitness\")\n",
    "plt.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual: \n",
      " or_(bf[5], and_(and_(bf[1], bf[0]), greater_than(add(nf[2], nf[0]), sub(nf[5],\n",
      "add(nf[2], div(nf[0], sub(div(9.1885, sub(-6.9585, add(nf[2], nf[0]))),\n",
      "div(add(div(-6.9389, 9.1485), -2.4474), mul(div(nf[4], mul(nf[0], sub(nf[5],\n",
      "2.3597))), nf[6])))))))))\n",
      "\n",
      "Training Fitness:  0.26041253470844905\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "best = hof.items[0].phenotype\n",
    "print(\"Best individual: \\n\", \"\\n\".join(textwrap.wrap(best, 80)))\n",
    "print(\"\\nTraining Fitness: \", hof.items[0].fitness.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hof.items[0].phenotype, file=open(\"best_individual.txt\", \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data \n",
    "testDf = pd.read_csv('test.csv')\n",
    "testDf[CONTINUOUS_FEATURES] = stdScaler.transform(testDf[CONTINUOUS_FEATURES])\n",
    "testDf[ORDINAL_FEATURES] = minMaxScaler.transform(testDf[ORDINAL_FEATURES])\n",
    "\n",
    "X_test = testDf\n",
    "\n",
    "res = []\n",
    "\n",
    "for i, row in X_test.iterrows():\n",
    "    nf = row[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "    bf = row[BOOLEAN_FEATURES].to_numpy()\n",
    "\n",
    "    pred = gePredict(hof.items[0], nf, bf)\n",
    "    res.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df of index, output; index [0...n-1]; output is above\n",
    "\n",
    "outputDf = pd.DataFrame(res, columns=[\"output\"])\n",
    "outputDf[\"index\"] = outputDf.index\n",
    "\n",
    "outputDf = outputDf[[\"index\", \"output\"]]\n",
    "\n",
    "outputDf.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
