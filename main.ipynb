{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features exploration\n",
    "\n",
    "All features given are numerical (including but not limited to boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
       "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n",
       "       'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "trainDf = pd.read_csv('train.csv')\n",
    "trainDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data (Not including boolean)\n",
    "\n",
    "- BMI\n",
    "- GenHlth\n",
    "- MentHlth\n",
    "- PhysHlth\n",
    "- Age\n",
    "- Education\n",
    "- Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>29.447441</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>2.702102</td>\n",
       "      <td>3.617017</td>\n",
       "      <td>5.195954</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>8.376041</td>\n",
       "      <td>4.958548</td>\n",
       "      <td>5.852836</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>7.080019</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>1.106379</td>\n",
       "      <td>7.997166</td>\n",
       "      <td>9.538762</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>2.920253</td>\n",
       "      <td>1.018217</td>\n",
       "      <td>2.131317</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck          BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035    29.447441     0.473225   \n",
       "std       0.499857     0.500009     0.164889     7.080019     0.499332   \n",
       "min       0.000000     0.000000     0.000000    14.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000    25.000000     0.000000   \n",
       "50%       1.000000     0.000000     1.000000    28.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000    33.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000    98.000000     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     2.702102     3.617017     5.195954   \n",
       "std       0.398785  ...     0.280213     1.106379     7.997166     9.538762   \n",
       "min       0.000000  ...     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     2.000000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     3.000000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     3.000000     2.000000     5.000000   \n",
       "max       1.000000  ...     1.000000     5.000000    30.000000    30.000000   \n",
       "\n",
       "          DiffWalk          Sex          Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441     8.376041     4.958548     5.852836   \n",
       "std       0.405240     0.497279     2.920253     1.018217     2.131317   \n",
       "min       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "25%       0.000000     0.000000     7.000000     4.000000     4.000000   \n",
       "50%       0.000000     0.000000     9.000000     5.000000     6.000000   \n",
       "75%       0.000000     1.000000    10.000000     6.000000     8.000000   \n",
       "max       1.000000     1.000000    13.000000     6.000000     8.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 7\n",
      "Number of boolean features: 14\n"
     ]
    }
   ],
   "source": [
    "CONTINUOUS_FEATURES = [\"BMI\", \"Age\"]\n",
    "ORDINAL_FEATURES = [\"GenHlth\", \"MentHlth\", \"PhysHlth\", \"Education\", \"Income\"]\n",
    "\n",
    "BOOLEAN_FEATURES = [\n",
    "    col\n",
    "    for col in trainDf.columns\n",
    "    if col not in CONTINUOUS_FEATURES\n",
    "    and col not in ORDINAL_FEATURES\n",
    "    and col != \"output\"\n",
    "]\n",
    "\n",
    "print(f\"Number of numerical features: {len(CONTINUOUS_FEATURES) + len(ORDINAL_FEATURES)}\")\n",
    "print(f\"Number of boolean features: {len(BOOLEAN_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "Check outliner of BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class Outliner:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df: DataFrame):\n",
    "        self.Q1 = df.quantile(0.25)\n",
    "        self.Q3 = df.quantile(0.75)\n",
    "        self.IQR = self.Q3 - self.Q1\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        df[((df < (self.Q1 - 1.5 * self.IQR)) | (df > (self.Q3 + 1.5 * self.IQR)))] = (\n",
    "            np.nan\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>-2.113872e-16</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.425526</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.173198</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>-5.214217e-17</td>\n",
       "      <td>0.791710</td>\n",
       "      <td>0.693262</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>0.276595</td>\n",
       "      <td>0.266572</td>\n",
       "      <td>0.317959</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.203643</td>\n",
       "      <td>0.304474</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.182052e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.526073e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.282303e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.712529e-01</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.044606e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136872e-01</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.018222e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.561573e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.683498e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.583567e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck           BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5.042000e+03  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035 -2.113872e-16     0.473225   \n",
       "std       0.499857     0.500009     0.164889  1.000099e+00     0.499332   \n",
       "min       0.000000     0.000000     0.000000 -2.182052e+00     0.000000   \n",
       "25%       0.000000     0.000000     1.000000 -6.282303e-01     0.000000   \n",
       "50%       1.000000     0.000000     1.000000 -2.044606e-01     0.000000   \n",
       "75%       1.000000     1.000000     1.000000  5.018222e-01     1.000000   \n",
       "max       1.000000     1.000000     1.000000  9.683498e+00     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     0.425526     0.120567     0.173198   \n",
       "std       0.398785  ...     0.280213     0.276595     0.266572     0.317959   \n",
       "min       0.000000  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     0.250000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     0.500000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     0.500000     0.066667     0.166667   \n",
       "max       1.000000  ...     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          DiffWalk          Sex           Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5.042000e+03  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441 -5.214217e-17     0.791710     0.693262   \n",
       "std       0.405240     0.497279  1.000099e+00     0.203643     0.304474   \n",
       "min       0.000000     0.000000 -2.526073e+00     0.000000     0.000000   \n",
       "25%       0.000000     0.000000 -4.712529e-01     0.600000     0.428571   \n",
       "50%       0.000000     0.000000  2.136872e-01     0.800000     0.714286   \n",
       "75%       0.000000     1.000000  5.561573e-01     1.000000     1.000000   \n",
       "max       1.000000     1.000000  1.583567e+00     1.000000     1.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "trainDf[CONTINUOUS_FEATURES] = stdScaler.fit_transform(trainDf[CONTINUOUS_FEATURES])\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "trainDf[ORDINAL_FEATURES] = minMaxScaler.fit_transform(trainDf[ORDINAL_FEATURES])\n",
    "\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammatical Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape\n",
      "/home/tu/code-py/evolutionary-computation/mid-project\n"
     ]
    }
   ],
   "source": [
    "# switch directory to use grape\n",
    "%cd ../grape\n",
    "\n",
    "# import grape and necessary functions\n",
    "import grape\n",
    "from algorithms import ge_eaSimpleWithElitism\n",
    "from functions import pdiv\n",
    "\n",
    "\n",
    "# switch back to the original directory\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "POPULATION_SIZE = 1000\n",
    "MAX_GENERATIONS = 100\n",
    "P_CROSSOVER = 0.8\n",
    "P_MUTATION = 0.01\n",
    "HALLOFFAME_SIZE = max(round(0.01 * POPULATION_SIZE), 1)  # it should be at least 1\n",
    "ELITE_SIZE = min(round(0.01 * POPULATION_SIZE), HALLOFFAME_SIZE)\n",
    "\n",
    "CODON_CONSUMPTION = \"lazy\"\n",
    "GENOME_REPRESENTATION = \"list\"\n",
    "MAX_GENOME_LENGTH = None\n",
    "\n",
    "MAX_INIT_TREE_DEPTH = 17\n",
    "MIN_INIT_TREE_DEPTH = 5\n",
    "MAX_TREE_DEPTH = 90\n",
    "MAX_WRAPS = 0\n",
    "CODON_SIZE = 255\n",
    "\n",
    "REPORT_ITEMS = [\n",
    "    \"gen\",\n",
    "    \"invalid\",\n",
    "    \"avg\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"fitness_test\",\n",
    "    \"best_ind_length\",\n",
    "    \"avg_length\",\n",
    "    \"best_ind_nodes\",\n",
    "    \"avg_nodes\",\n",
    "    \"best_ind_depth\",\n",
    "    \"avg_depth\",\n",
    "    \"avg_used_codons\",\n",
    "    \"best_ind_used_codons\",\n",
    "    \"selection_time\",\n",
    "    \"generation_time\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['add(<number_value>, <number_value>)', 'non-terminal', 2, 0, True, 3],\n",
       "  ['sub(<number_value>, <number_value>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['mul(<number_value>, <number_value>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['div(<number_value>, <number_value>)', 'non-terminal', 2, 3, True, 3],\n",
       "  ['abs(<number_value>)', 'non-terminal', 1, 4, True, 3],\n",
       "  ['sigmoid(<number_value>)', 'non-terminal', 1, 5, True, 3],\n",
       "  ['tanh(<number_value>)', 'non-terminal', 1, 6, True, 3],\n",
       "  ['relu(<number_value>)', 'non-terminal', 1, 7, True, 3],\n",
       "  ['swish(<number_value>)', 'non-terminal', 1, 8, True, 3],\n",
       "  ['np.where((<logic_op>), (<number_value>), (<number_value>))',\n",
       "   'non-terminal',\n",
       "   3,\n",
       "   9,\n",
       "   True,\n",
       "   3]],\n",
       " [['<compare_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['and_(<logic_op>, <logic_op>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['or_(<logic_op>, <logic_op>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['xor(<logic_op>, <logic_op>)', 'non-terminal', 2, 3, True, 3],\n",
       "  ['not_(<logic_op>)', 'non-terminal', 1, 4, True, 3],\n",
       "  ['<bool_feat>', 'non-terminal', 1, 5, False, 2]],\n",
       " [['greater_than(<number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   2,\n",
       "   0,\n",
       "   True,\n",
       "   3],\n",
       "  ['less_than(<number_value>, <number_value>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['in_range(<number_value>, <number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   3,\n",
       "   2,\n",
       "   True,\n",
       "   3]],\n",
       " [['<number_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['<number_feat>', 'non-terminal', 1, 1, False, 2],\n",
       "  ['<number>', 'non-terminal', 1, 2, False, 3],\n",
       "  ['<logic_op>', 'non-terminal', 1, 3, True, 3]],\n",
       " [['<d>.<d><d><d><d>', 'non-terminal', 5, 0, False, 2],\n",
       "  ['-<d>.<d><d><d><d>', 'non-terminal', 5, 1, False, 2]],\n",
       " [['0', 'terminal', 0, 0, False, 1],\n",
       "  ['1', 'terminal', 0, 1, False, 1],\n",
       "  ['2', 'terminal', 0, 2, False, 1],\n",
       "  ['3', 'terminal', 0, 3, False, 1],\n",
       "  ['4', 'terminal', 0, 4, False, 1],\n",
       "  ['5', 'terminal', 0, 5, False, 1],\n",
       "  ['6', 'terminal', 0, 6, False, 1],\n",
       "  ['7', 'terminal', 0, 7, False, 1],\n",
       "  ['8', 'terminal', 0, 8, False, 1],\n",
       "  ['9', 'terminal', 0, 9, False, 1]],\n",
       " [['nf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['nf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['nf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['nf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['nf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['nf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['nf[6]', 'terminal', 0, 6, False, 1]],\n",
       " [['bf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['bf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['bf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['bf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['bf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['bf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['bf[6]', 'terminal', 0, 6, False, 1],\n",
       "  ['bf[7]', 'terminal', 0, 7, False, 1],\n",
       "  ['bf[8]', 'terminal', 0, 8, False, 1],\n",
       "  ['bf[9]', 'terminal', 0, 9, False, 1],\n",
       "  ['bf[10]', 'terminal', 0, 10, False, 1],\n",
       "  ['bf[11]', 'terminal', 0, 11, False, 1],\n",
       "  ['bf[12]', 'terminal', 0, 12, False, 1],\n",
       "  ['bf[13]', 'terminal', 0, 13, False, 1]]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = grape.Grammar(\"./gramma.bnf\")\n",
    "grammar.production_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# logic op\n",
    "def and_(a, b):\n",
    "    return np.logical_and(a, b)\n",
    "def or_(a, b):\n",
    "    return np.logical_or(a, b)\n",
    "def xor(a, b):\n",
    "    return np.logical_xor(a, b)\n",
    "def not_(a):\n",
    "    return np.logical_not(a)\n",
    "\n",
    "# compare op\n",
    "def greater_than(a, b):\n",
    "    return (a > b)\n",
    "def less_than(a, b):\n",
    "    return (a < b)\n",
    "def in_range(a, b, c):\n",
    "    return np.logical_and(a > b, a < c)\n",
    "\n",
    "# number op\n",
    "def add(a, b):\n",
    "    return (a + b)\n",
    "def sub(a, b):\n",
    "    return (a - b)\n",
    "def mul(a, b):\n",
    "    return (a * b)\n",
    "def div(a, b):\n",
    "    return pdiv(a, b)\n",
    "def abs(a):\n",
    "    return np.abs(a)\n",
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "def tanh(a):\n",
    "    return np.tanh(a)\n",
    "def relu(a):\n",
    "    return np.maximum(0, a)\n",
    "def swish(a):\n",
    "    return a * sigmoid(a)\n",
    "\n",
    "\n",
    "class GE_ExecuteError(Exception):\n",
    "    # take a message as input\n",
    "    def __init__(self, message=\"Error during the execution of the individual\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "    pass\n",
    "\n",
    "def gePredictProba(individual, nf, bf):\n",
    "    \"\"\"Predict if a case is positive or negative using ge and the individual.\n",
    "\n",
    "    Args:\n",
    "        individual (_type_): a valid GE individual\n",
    "        nf (_type_): numerical features\n",
    "        bf (_type_): boolean features\n",
    "\n",
    "    Raises:\n",
    "        GE_ExecuteError: if error happens during the execution of the individual\n",
    "\n",
    "    Returns:\n",
    "        float: the probability of the case being positive [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    nf = np.array(nf)\n",
    "    bf = np.array(bf)\n",
    "\n",
    "    assert nf.ndim == bf.ndim, \"Numerical and Boolean data must have the same number of dimensions\"\n",
    "\n",
    "    # execute\n",
    "    try:\n",
    "        if nf.ndim == 1:\n",
    "            res = eval(individual.phenotype)\n",
    "            pred = 1 if res > 0 else 0\n",
    "            return pred\n",
    "\n",
    "        if nf.ndim == 2:\n",
    "            assert nf.shape[0] == bf.shape[0], \"Numerical and Boolean data must have the same number of samples\"\n",
    "\n",
    "            nf = nf.T\n",
    "            bf = bf.T\n",
    "\n",
    "            proba = eval(individual.phenotype)\n",
    "            proba = sigmoid(proba)\n",
    "            return proba\n",
    "\n",
    "        raise NotImplementedError(\"Data with more than 2 dimensions is not supported\")\n",
    "\n",
    "    except (\n",
    "        FloatingPointError,\n",
    "        ZeroDivisionError,\n",
    "        OverflowError,\n",
    "        MemoryError,\n",
    "        IndexError,\n",
    "        TypeError,\n",
    "    ) as e:\n",
    "        raise GE_ExecuteError(str(e))\n",
    "\n",
    "def gePredict(individual, nf, bf):\n",
    "    proba = gePredictProba(individual, nf, bf)\n",
    "    return np.round(proba).astype(int)\n",
    "\n",
    "def featUsedFitness(individual, x):\n",
    "    L = 1\n",
    "    k = 0.7\n",
    "\n",
    "    totalFeat: int = x.shape[1]\n",
    "    x0 = totalFeat // 2\n",
    "\n",
    "    featUsed = 0\n",
    "    for i in range(len(CONTINUOUS_FEATURES) + len(ORDINAL_FEATURES)):\n",
    "        if f\"nf[{i}]\" in individual.phenotype:\n",
    "            featUsed += 1\n",
    "    for i in range(len(BOOLEAN_FEATURES)):\n",
    "        if f\"bf[{i}]\" in individual.phenotype:\n",
    "            featUsed += 1\n",
    "            \n",
    "    if featUsed <= x0:\n",
    "        return L * featUsed / (2 * x0)\n",
    "            \n",
    "\n",
    "    return L / (1 + np.exp(-k * (featUsed - x0)))\n",
    "\n",
    "def errorRateFitness(individual, x, Y):\n",
    "    nf = x[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "    bf = x[BOOLEAN_FEATURES].to_numpy()\n",
    "\n",
    "    proba = gePredictProba(individual, nf, bf)\n",
    "    \n",
    "    mse = np.mean((Y - proba) ** 2)\n",
    "\n",
    "    return mse\n",
    "\n",
    "def fitness(individual, points):\n",
    "    INVALID = np.nan, np.nan\n",
    "\n",
    "    if individual.invalid:\n",
    "        return INVALID\n",
    "\n",
    "    x, Y = points\n",
    "\n",
    "    featFitness = featUsedFitness(individual, x)\n",
    "    \n",
    "    try:\n",
    "        errRate = errorRateFitness(individual, x, Y)\n",
    "    except GE_ExecuteError:\n",
    "        return INVALID\n",
    "\n",
    "    return (errRate, featFitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/micromamba/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/tu/micromamba/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# define a single objective, minimising fitness strategy:\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, 0.05))\n",
    "creator.create(\"Individual\", grape.Individual, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox.register(\"populationCreator\", grape.sensible_initialisation, creator.Individual)\n",
    "toolbox.register(\"evaluate\", fitness)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=7)  # nsga2\n",
    "toolbox.register(\"mate\", grape.crossover_onepoint)\n",
    "toolbox.register(\"mutate\", grape.mutation_int_flip_per_codon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "X_train = trainDf.drop(columns=[\"output\"])\n",
    "y_train = trainDf[\"output\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:124: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid them.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid them.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 0 , Best fitness = (np.float64(0.20762338497516478), 0.10000000000000002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 1 , Best fitness = (np.float64(0.20762338497516478), 0.10000000000000002) , Number of invalids = 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 2 , Best fitness = (np.float64(0.20679106383308388), 0.10000000000000002) , Number of invalids = 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 3 , Best fitness = (np.float64(0.20679106383308388), 0.10000000000000002) , Number of invalids = 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 4 , Best fitness = (np.float64(0.20679106383308388), 0.10000000000000002) , Number of invalids = 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 5 , Best fitness = (np.float64(0.20679106383308388), 0.10000000000000002) , Number of invalids = 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 6 , Best fitness = (np.float64(0.20679106383308388), 0.10000000000000002) , Number of invalids = 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 7 , Best fitness = (np.float64(0.2051697940793171), 0.15) , Number of invalids = 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 8 , Best fitness = (np.float64(0.20282895134091547), 0.10000000000000002) , Number of invalids = 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 9 , Best fitness = (np.float64(0.20282895134091547), 0.10000000000000002) , Number of invalids = 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 10 , Best fitness = (np.float64(0.20282895134091547), 0.10000000000000002) , Number of invalids = 90\n",
      "gen = 11 , Best fitness = (np.float64(0.1975919977042432), 0.15) , Number of invalids = 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 12 , Best fitness = (np.float64(0.1975919977042432), 0.15) , Number of invalids = 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 13 , Best fitness = (np.float64(0.19731591860608372), 0.15) , Number of invalids = 98\n",
      "gen = 14 , Best fitness = (np.float64(0.19731591860608372), 0.15) , Number of invalids = 90\n",
      "gen = 15 , Best fitness = (np.float64(0.19389972599849534), 0.15) , Number of invalids = 81\n",
      "gen = 16 , Best fitness = (np.float64(0.19389972599849534), 0.15) , Number of invalids = 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 17 , Best fitness = (np.float64(0.19323010107955066), 0.15) , Number of invalids = 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 18 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 19 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 20 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 21 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 22 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 23 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 24 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 25 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 26 , Best fitness = (np.float64(0.18576164103368034), 0.20000000000000004) , Number of invalids = 27\n",
      "gen = 27 , Best fitness = (np.float64(0.1857382161251512), 0.20000000000000004) , Number of invalids = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 28 , Best fitness = (np.float64(0.1857382161251512), 0.20000000000000004) , Number of invalids = 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 29 , Best fitness = (np.float64(0.18559273129672016), 0.20000000000000004) , Number of invalids = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 30 , Best fitness = (np.float64(0.18559273129672016), 0.20000000000000004) , Number of invalids = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 31 , Best fitness = (np.float64(0.18559273129672016), 0.20000000000000004) , Number of invalids = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 32 , Best fitness = (np.float64(0.1843408087389109), 0.20000000000000004) , Number of invalids = 40\n",
      "gen = 33 , Best fitness = (np.float64(0.1843408087389109), 0.20000000000000004) , Number of invalids = 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 34 , Best fitness = (np.float64(0.1843408087389109), 0.20000000000000004) , Number of invalids = 59\n",
      "gen = 35 , Best fitness = (np.float64(0.1843408087389109), 0.20000000000000004) , Number of invalids = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 36 , Best fitness = (np.float64(0.18432367502147723), 0.20000000000000004) , Number of invalids = 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 37 , Best fitness = (np.float64(0.18418400309320365), 0.20000000000000004) , Number of invalids = 71\n",
      "gen = 38 , Best fitness = (np.float64(0.1805139639920503), 0.25) , Number of invalids = 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 39 , Best fitness = (np.float64(0.1805139639920503), 0.25) , Number of invalids = 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 40 , Best fitness = (np.float64(0.1805139639920503), 0.25) , Number of invalids = 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 41 , Best fitness = (np.float64(0.1805139639920503), 0.25) , Number of invalids = 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 42 , Best fitness = (np.float64(0.1805139639920503), 0.25) , Number of invalids = 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 43 , Best fitness = (np.float64(0.18030913367141477), 0.25) , Number of invalids = 108\n",
      "gen = 44 , Best fitness = (np.float64(0.18030913367141477), 0.25) , Number of invalids = 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 45 , Best fitness = (np.float64(0.18030913367141477), 0.25) , Number of invalids = 113\n",
      "gen = 46 , Best fitness = (np.float64(0.17943282658857293), 0.25) , Number of invalids = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 47 , Best fitness = (np.float64(0.17725891387374196), 0.25) , Number of invalids = 91\n",
      "gen = 48 , Best fitness = (np.float64(0.17725891387374196), 0.25) , Number of invalids = 86\n",
      "gen = 49 , Best fitness = (np.float64(0.17725891387374196), 0.25) , Number of invalids = 111\n",
      "gen = 50 , Best fitness = (np.float64(0.17725891387374196), 0.25) , Number of invalids = 123\n",
      "gen = 51 , Best fitness = (np.float64(0.17725891387374196), 0.25) , Number of invalids = 119\n",
      "gen = 52 , Best fitness = (np.float64(0.17703162398283318), 0.25) , Number of invalids = 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 53 , Best fitness = (np.float64(0.17703162398283318), 0.25) , Number of invalids = 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 54 , Best fitness = (np.float64(0.17703162398283318), 0.25) , Number of invalids = 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 55 , Best fitness = (np.float64(0.17674399286205675), 0.25) , Number of invalids = 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 56 , Best fitness = (np.float64(0.17674399286205675), 0.25) , Number of invalids = 123\n",
      "gen = 57 , Best fitness = (np.float64(0.17674399286205675), 0.25) , Number of invalids = 123\n",
      "gen = 58 , Best fitness = (np.float64(0.17674399286205675), 0.25) , Number of invalids = 118\n",
      "gen = 59 , Best fitness = (np.float64(0.17674399286205675), 0.25) , Number of invalids = 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 60 , Best fitness = (np.float64(0.1767404148988454), 0.3) , Number of invalids = 123\n",
      "gen = 61 , Best fitness = (np.float64(0.1764139414505856), 0.3) , Number of invalids = 108\n",
      "gen = 62 , Best fitness = (np.float64(0.1764139414505856), 0.3) , Number of invalids = 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 63 , Best fitness = (np.float64(0.17602150695549842), 0.3) , Number of invalids = 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 64 , Best fitness = (np.float64(0.17602150695549842), 0.3) , Number of invalids = 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 65 , Best fitness = (np.float64(0.1759480374142715), 0.3) , Number of invalids = 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 66 , Best fitness = (np.float64(0.1759480374142715), 0.3) , Number of invalids = 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 67 , Best fitness = (np.float64(0.1759480374142715), 0.3) , Number of invalids = 106\n",
      "gen = 68 , Best fitness = (np.float64(0.17594417959114983), 0.3) , Number of invalids = 91\n",
      "gen = 69 , Best fitness = (np.float64(0.1755199867950642), 0.3499999999999999) , Number of invalids = 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 70 , Best fitness = (np.float64(0.17551414493428522), 0.3499999999999999) , Number of invalids = 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 71 , Best fitness = (np.float64(0.17551360482783873), 0.4000000000000001) , Number of invalids = 81\n",
      "gen = 72 , Best fitness = (np.float64(0.17547379276409591), 0.3499999999999999) , Number of invalids = 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 73 , Best fitness = (np.float64(0.17547379276409591), 0.3499999999999999) , Number of invalids = 49\n",
      "gen = 74 , Best fitness = (np.float64(0.17528476731330006), 0.3499999999999999) , Number of invalids = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 75 , Best fitness = (np.float64(0.17528476731330006), 0.3499999999999999) , Number of invalids = 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 76 , Best fitness = (np.float64(0.17518422946770212), 0.3499999999999999) , Number of invalids = 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 77 , Best fitness = (np.float64(0.17518422946770212), 0.3499999999999999) , Number of invalids = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 78 , Best fitness = (np.float64(0.17518422946770212), 0.3499999999999999) , Number of invalids = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 79 , Best fitness = (np.float64(0.17517703783813685), 0.3499999999999999) , Number of invalids = 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 80 , Best fitness = (np.float64(0.1751750917402346), 0.3499999999999999) , Number of invalids = 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 81 , Best fitness = (np.float64(0.17508536629369056), 0.3499999999999999) , Number of invalids = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 82 , Best fitness = (np.float64(0.17421170062508853), 0.3499999999999999) , Number of invalids = 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 83 , Best fitness = (np.float64(0.17421170062508853), 0.3499999999999999) , Number of invalids = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 84 , Best fitness = (np.float64(0.17421170062508853), 0.3499999999999999) , Number of invalids = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 85 , Best fitness = (np.float64(0.17421117561322058), 0.3499999999999999) , Number of invalids = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 86 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 87 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 88 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 89 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 90 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 91 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 92 , Best fitness = (np.float64(0.1742072257007249), 0.3499999999999999) , Number of invalids = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 93 , Best fitness = (np.float64(0.1741969640218515), 0.3499999999999999) , Number of invalids = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 94 , Best fitness = (np.float64(0.1741969640218515), 0.3499999999999999) , Number of invalids = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 95 , Best fitness = (np.float64(0.17401553693682809), 0.3499999999999999) , Number of invalids = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 96 , Best fitness = (np.float64(0.17401553693682809), 0.3499999999999999) , Number of invalids = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 97 , Best fitness = (np.float64(0.17401553693682809), 0.3499999999999999) , Number of invalids = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 98 , Best fitness = (np.float64(0.17401553693682809), 0.3499999999999999) , Number of invalids = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/home/tu/code-py/evolutionary-computation/grape/algorithms.py:243: UserWarning: Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\n",
      "  warnings.warn(\"Warning: There are valid individuals with fitness = NaN in the population. We will avoid in the statistics.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 99 , Best fitness = (np.float64(0.17401553693682809), 0.3499999999999999) , Number of invalids = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n",
      "/tmp/ipykernel_144934/977434363.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 100 , Best fitness = (np.float64(0.17401553693682809), 0.4000000000000001) , Number of invalids = 0\n"
     ]
    }
   ],
   "source": [
    "# population and hall of fame:\n",
    "population = toolbox.populationCreator(\n",
    "    pop_size=POPULATION_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    min_init_depth=MIN_INIT_TREE_DEPTH,\n",
    "    max_init_depth=MAX_INIT_TREE_DEPTH,\n",
    "    codon_size=CODON_SIZE,\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    ")\n",
    "hof = tools.HallOfFame(HALLOFFAME_SIZE)\n",
    "\n",
    "# prepare the statistics object:\n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
    "stats_feat_used = tools.Statistics(lambda ind: ind.fitness.values[1])\n",
    "\n",
    "stats = tools.MultiStatistics(fitness=stats_fit, feat_used=stats_feat_used)\n",
    "stats.register(\"avg\", np.nanmean)\n",
    "stats.register(\"std\", np.nanstd)\n",
    "stats.register(\"min\", np.nanmin)\n",
    "stats.register(\"max\", np.nanmax)\n",
    "\n",
    "# run the algorithm:\n",
    "population, logbook = ge_eaSimpleWithElitism(\n",
    "    population,\n",
    "    toolbox,\n",
    "    cxpb=P_CROSSOVER,\n",
    "    mutpb=P_MUTATION,\n",
    "    ngen=MAX_GENERATIONS,\n",
    "    elite_size=ELITE_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    codon_size=CODON_SIZE,\n",
    "    max_tree_depth=MAX_TREE_DEPTH,\n",
    "    max_genome_length=MAX_GENOME_LENGTH,\n",
    "    points_train=[X_train, y_train],\n",
    "    # points_test=[X_test, y_test],\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    report_items=REPORT_ITEMS,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    "    stats=stats,\n",
    "    halloffame=hof,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7a9f9ea80b80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "chapter_fitness = logbook.chapters[\"fitness\"]\n",
    "\n",
    "gen = chapter_fitness.select(\"gen\")\n",
    "fit_mins = chapter_fitness.select(\"min\")\n",
    "fit_avgs = chapter_fitness.select(\"avg\")\n",
    "\n",
    "plt.plot(gen, fit_mins, \"b-\", label=\"Best Fitness\")\n",
    "plt.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual: \n",
      " sub(tanh(tanh(nf[0])), sub(sub(nf[6], np.where((not_(bf[0])), (-0.5044),\n",
      "(np.where((not_(bf[2])), (-0.6394), (nf[2]))))), np.where((not_(bf[1])),\n",
      "(np.where((not_(bf[5])), (tanh(-0.6040)), (nf[2]))), (np.where((not_(bf[1])),\n",
      "(np.where((not_(bf[5])), (tanh(-0.6040)), (nf[2]))), (np.where((not_(bf[1])),\n",
      "(-0.4120), (np.where((not_(bf[5])), (abs(nf[2])), (np.where((not_(bf[5])),\n",
      "(abs(nf[1])), (tanh(add(0.6946, nf[6]))))))))))))))\n",
      "\n",
      "Training Fitness:  0.17401553693682809\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "best = hof.items[0].phenotype\n",
    "print(\"Best individual: \\n\", \"\\n\".join(textwrap.wrap(best, 80)))\n",
    "print(\"\\nTraining Fitness: \", hof.items[0].fitness.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hof.items[0].phenotype, file=open(\"best_individual.txt\", \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data \n",
    "testDf = pd.read_csv('test.csv')\n",
    "testDf[CONTINUOUS_FEATURES] = stdScaler.transform(testDf[CONTINUOUS_FEATURES])\n",
    "testDf[ORDINAL_FEATURES] = minMaxScaler.transform(testDf[ORDINAL_FEATURES])\n",
    "\n",
    "X_test = testDf\n",
    "\n",
    "nf = X_test[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "bf = X_test[BOOLEAN_FEATURES].to_numpy()\n",
    "\n",
    "res: list = gePredict(hof.items[0], nf, bf) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df of index, output; index [0...n-1]; output is above\n",
    "\n",
    "outputDf = pd.DataFrame(res, columns=[\"output\"])\n",
    "outputDf[\"index\"] = outputDf.index\n",
    "\n",
    "outputDf = outputDf[[\"index\", \"output\"]]\n",
    "\n",
    "outputDf.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
