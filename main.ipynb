{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features exploration\n",
    "\n",
    "All features given are numerical (including but not limited to boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
       "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n",
       "       'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "trainDf = pd.read_csv('train.csv')\n",
    "trainDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data (Not including boolean)\n",
    "\n",
    "- BMI\n",
    "- GenHlth\n",
    "- MentHlth\n",
    "- PhysHlth\n",
    "- Age\n",
    "- Education\n",
    "- Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>29.447441</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>2.702102</td>\n",
       "      <td>3.617017</td>\n",
       "      <td>5.195954</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>8.376041</td>\n",
       "      <td>4.958548</td>\n",
       "      <td>5.852836</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>7.080019</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>1.106379</td>\n",
       "      <td>7.997166</td>\n",
       "      <td>9.538762</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>2.920253</td>\n",
       "      <td>1.018217</td>\n",
       "      <td>2.131317</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck          BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035    29.447441     0.473225   \n",
       "std       0.499857     0.500009     0.164889     7.080019     0.499332   \n",
       "min       0.000000     0.000000     0.000000    14.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000    25.000000     0.000000   \n",
       "50%       1.000000     0.000000     1.000000    28.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000    33.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000    98.000000     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     2.702102     3.617017     5.195954   \n",
       "std       0.398785  ...     0.280213     1.106379     7.997166     9.538762   \n",
       "min       0.000000  ...     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     2.000000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     3.000000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     3.000000     2.000000     5.000000   \n",
       "max       1.000000  ...     1.000000     5.000000    30.000000    30.000000   \n",
       "\n",
       "          DiffWalk          Sex          Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441     8.376041     4.958548     5.852836   \n",
       "std       0.405240     0.497279     2.920253     1.018217     2.131317   \n",
       "min       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "25%       0.000000     0.000000     7.000000     4.000000     4.000000   \n",
       "50%       0.000000     0.000000     9.000000     5.000000     6.000000   \n",
       "75%       0.000000     1.000000    10.000000     6.000000     8.000000   \n",
       "max       1.000000     1.000000    13.000000     6.000000     8.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 7\n",
      "Number of boolean features: 14\n"
     ]
    }
   ],
   "source": [
    "CONTINUOUS_FEATURES = [\"BMI\", \"Age\"]\n",
    "ORDINAL_FEATURES = [\"GenHlth\", \"MentHlth\", \"PhysHlth\", \"Education\", \"Income\"]\n",
    "\n",
    "BOOLEAN_FEATURES = [\n",
    "    col\n",
    "    for col in trainDf.columns\n",
    "    if col not in CONTINUOUS_FEATURES\n",
    "    and col not in ORDINAL_FEATURES\n",
    "    and col != \"output\"\n",
    "]\n",
    "\n",
    "print(f\"Number of numerical features: {len(CONTINUOUS_FEATURES) + len(ORDINAL_FEATURES)}\")\n",
    "print(f\"Number of boolean features: {len(BOOLEAN_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "Check outliner of BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class Outliner:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df: DataFrame):\n",
    "        self.Q1 = df.quantile(0.25)\n",
    "        self.Q3 = df.quantile(0.75)\n",
    "        self.IQR = self.Q3 - self.Q1\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        df[((df < (self.Q1 - 1.5 * self.IQR)) | (df > (self.Q3 + 1.5 * self.IQR)))] = (\n",
    "            np.nan\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5.042000e+03</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "      <td>5042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>-2.113872e-16</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.728877</td>\n",
       "      <td>0.616025</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.425526</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.173198</td>\n",
       "      <td>0.207061</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>-5.214217e-17</td>\n",
       "      <td>0.791710</td>\n",
       "      <td>0.693262</td>\n",
       "      <td>0.356010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.444583</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.398785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280213</td>\n",
       "      <td>0.276595</td>\n",
       "      <td>0.266572</td>\n",
       "      <td>0.317959</td>\n",
       "      <td>0.405240</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>1.000099e+00</td>\n",
       "      <td>0.203643</td>\n",
       "      <td>0.304474</td>\n",
       "      <td>0.478866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.182052e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.526073e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.282303e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.712529e-01</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.044606e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136872e-01</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.018222e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.561573e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.683498e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.583567e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HighBP     HighChol    CholCheck           BMI       Smoker  \\\n",
       "count  5042.000000  5042.000000  5042.000000  5.042000e+03  5042.000000   \n",
       "mean      0.513883     0.493653     0.972035 -2.113872e-16     0.473225   \n",
       "std       0.499857     0.500009     0.164889  1.000099e+00     0.499332   \n",
       "min       0.000000     0.000000     0.000000 -2.182052e+00     0.000000   \n",
       "25%       0.000000     0.000000     1.000000 -6.282303e-01     0.000000   \n",
       "50%       1.000000     0.000000     1.000000 -2.044606e-01     0.000000   \n",
       "75%       1.000000     1.000000     1.000000  5.018222e-01     1.000000   \n",
       "max       1.000000     1.000000     1.000000  9.683498e+00     1.000000   \n",
       "\n",
       "            Stroke  HeartDiseaseorAttack  PhysActivity       Fruits  \\\n",
       "count  5042.000000           5042.000000   5042.000000  5042.000000   \n",
       "mean      0.050377              0.133082      0.728877     0.616025   \n",
       "std       0.218743              0.339697      0.444583     0.486400   \n",
       "min       0.000000              0.000000      0.000000     0.000000   \n",
       "25%       0.000000              0.000000      0.000000     0.000000   \n",
       "50%       0.000000              0.000000      1.000000     1.000000   \n",
       "75%       0.000000              0.000000      1.000000     1.000000   \n",
       "max       1.000000              1.000000      1.000000     1.000000   \n",
       "\n",
       "           Veggies  ...  NoDocbcCost      GenHlth     MentHlth     PhysHlth  \\\n",
       "count  5042.000000  ...  5042.000000  5042.000000  5042.000000  5042.000000   \n",
       "mean      0.801666  ...     0.085879     0.425526     0.120567     0.173198   \n",
       "std       0.398785  ...     0.280213     0.276595     0.266572     0.317959   \n",
       "min       0.000000  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000  ...     0.000000     0.250000     0.000000     0.000000   \n",
       "50%       1.000000  ...     0.000000     0.500000     0.000000     0.000000   \n",
       "75%       1.000000  ...     0.000000     0.500000     0.066667     0.166667   \n",
       "max       1.000000  ...     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          DiffWalk          Sex           Age    Education       Income  \\\n",
       "count  5042.000000  5042.000000  5.042000e+03  5042.000000  5042.000000   \n",
       "mean      0.207061     0.447441 -5.214217e-17     0.791710     0.693262   \n",
       "std       0.405240     0.497279  1.000099e+00     0.203643     0.304474   \n",
       "min       0.000000     0.000000 -2.526073e+00     0.000000     0.000000   \n",
       "25%       0.000000     0.000000 -4.712529e-01     0.600000     0.428571   \n",
       "50%       0.000000     0.000000  2.136872e-01     0.800000     0.714286   \n",
       "75%       0.000000     1.000000  5.561573e-01     1.000000     1.000000   \n",
       "max       1.000000     1.000000  1.583567e+00     1.000000     1.000000   \n",
       "\n",
       "            output  \n",
       "count  5042.000000  \n",
       "mean      0.356010  \n",
       "std       0.478866  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "trainDf[CONTINUOUS_FEATURES] = stdScaler.fit_transform(trainDf[CONTINUOUS_FEATURES])\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "trainDf[ORDINAL_FEATURES] = minMaxScaler.fit_transform(trainDf[ORDINAL_FEATURES])\n",
    "\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammatical Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tu/code-py/evolutionary-computation/grape\n",
      "/home/tu/code-py/evolutionary-computation/mid-project\n"
     ]
    }
   ],
   "source": [
    "# switch directory to use grape\n",
    "%cd ../grape\n",
    "\n",
    "# import grape and necessary functions\n",
    "import grape\n",
    "from algorithms import ge_eaSimpleWithElitism\n",
    "\n",
    "# switch back to the original directory\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "POPULATION_SIZE = 1000\n",
    "MAX_GENERATIONS = 100\n",
    "P_CROSSOVER = 0.8\n",
    "P_MUTATION = 0.01\n",
    "HALLOFFAME_SIZE = max(round(0.01 * POPULATION_SIZE), 1)  # it should be at least 1\n",
    "ELITE_SIZE = min(round(0.01 * POPULATION_SIZE), HALLOFFAME_SIZE)\n",
    "\n",
    "CODON_CONSUMPTION = \"lazy\"\n",
    "GENOME_REPRESENTATION = \"list\"\n",
    "MAX_GENOME_LENGTH = None\n",
    "\n",
    "MAX_INIT_TREE_DEPTH = 13\n",
    "MIN_INIT_TREE_DEPTH = 3\n",
    "MAX_TREE_DEPTH = 90\n",
    "MAX_WRAPS = 0\n",
    "CODON_SIZE = 255\n",
    "\n",
    "REPORT_ITEMS = [\n",
    "    \"gen\",\n",
    "    \"invalid\",\n",
    "    \"avg\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"fitness_test\",\n",
    "    \"best_ind_length\",\n",
    "    \"avg_length\",\n",
    "    \"best_ind_nodes\",\n",
    "    \"avg_nodes\",\n",
    "    \"best_ind_depth\",\n",
    "    \"avg_depth\",\n",
    "    \"avg_used_codons\",\n",
    "    \"best_ind_used_codons\",\n",
    "    \"selection_time\",\n",
    "    \"generation_time\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['<compare_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['and_(<logic_op>, <logic_op>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['or_(<logic_op>, <logic_op>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['not_(<logic_op>)', 'non-terminal', 1, 3, True, 3],\n",
       "  ['<bool_feat>', 'non-terminal', 1, 4, False, 2]],\n",
       " [['greater_than(<number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   2,\n",
       "   0,\n",
       "   True,\n",
       "   3],\n",
       "  ['less_than(<number_value>, <number_value>)',\n",
       "   'non-terminal',\n",
       "   2,\n",
       "   1,\n",
       "   True,\n",
       "   3]],\n",
       " [['<number_op>', 'non-terminal', 1, 0, True, 4],\n",
       "  ['<number_feat>', 'non-terminal', 1, 1, False, 2],\n",
       "  ['<number>', 'non-terminal', 1, 2, False, 3]],\n",
       " [['add(<number_value>, <number_value>)', 'non-terminal', 2, 0, True, 3],\n",
       "  ['sub(<number_value>, <number_value>)', 'non-terminal', 2, 1, True, 3],\n",
       "  ['mul(<number_value>, <number_value>)', 'non-terminal', 2, 2, True, 3],\n",
       "  ['div(<number_value>, <number_value>)', 'non-terminal', 2, 3, True, 3]],\n",
       " [['<d>.<d><d><d><d>', 'non-terminal', 5, 0, False, 2],\n",
       "  ['-<d>.<d><d><d><d>', 'non-terminal', 5, 1, False, 2]],\n",
       " [['0', 'terminal', 0, 0, False, 1],\n",
       "  ['1', 'terminal', 0, 1, False, 1],\n",
       "  ['2', 'terminal', 0, 2, False, 1],\n",
       "  ['3', 'terminal', 0, 3, False, 1],\n",
       "  ['4', 'terminal', 0, 4, False, 1],\n",
       "  ['5', 'terminal', 0, 5, False, 1],\n",
       "  ['6', 'terminal', 0, 6, False, 1],\n",
       "  ['7', 'terminal', 0, 7, False, 1],\n",
       "  ['8', 'terminal', 0, 8, False, 1],\n",
       "  ['9', 'terminal', 0, 9, False, 1]],\n",
       " [['nf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['nf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['nf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['nf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['nf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['nf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['nf[6]', 'terminal', 0, 6, False, 1]],\n",
       " [['bf[0]', 'terminal', 0, 0, False, 1],\n",
       "  ['bf[1]', 'terminal', 0, 1, False, 1],\n",
       "  ['bf[2]', 'terminal', 0, 2, False, 1],\n",
       "  ['bf[3]', 'terminal', 0, 3, False, 1],\n",
       "  ['bf[4]', 'terminal', 0, 4, False, 1],\n",
       "  ['bf[5]', 'terminal', 0, 5, False, 1],\n",
       "  ['bf[6]', 'terminal', 0, 6, False, 1],\n",
       "  ['bf[7]', 'terminal', 0, 7, False, 1],\n",
       "  ['bf[8]', 'terminal', 0, 8, False, 1],\n",
       "  ['bf[9]', 'terminal', 0, 9, False, 1],\n",
       "  ['bf[10]', 'terminal', 0, 10, False, 1],\n",
       "  ['bf[11]', 'terminal', 0, 11, False, 1],\n",
       "  ['bf[12]', 'terminal', 0, 12, False, 1],\n",
       "  ['bf[13]', 'terminal', 0, 13, False, 1]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = grape.Grammar(\"./gramma.bnf\")\n",
    "grammar.production_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def and_(a, b):\n",
    "    return (a and b)\n",
    "def or_(a, b):\n",
    "    return (a or b)\n",
    "def not_(a):\n",
    "    return not (a)\n",
    "\n",
    "def greater_than(a, b):\n",
    "    return (a > b)\n",
    "def less_than(a, b):\n",
    "    return (a < b)\n",
    "\n",
    "def add(a, b):\n",
    "    return (a + b)\n",
    "def sub(a, b):\n",
    "    return (a - b)\n",
    "def mul(a, b):\n",
    "    return (a * b)\n",
    "def div(a, b):\n",
    "    if b == 0:\n",
    "        return 1\n",
    "    return (a / b)\n",
    "\n",
    "\n",
    "class GE_ExecuteError(Exception):\n",
    "    # take a message as input\n",
    "    def __init__(self, message=\"Error during the execution of the individual\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "    pass\n",
    "\n",
    "def gePredict(individual, nf, bf):\n",
    "    \"\"\"Predict if a case is positive or negative using ge and the individual.\n",
    "\n",
    "    Args:\n",
    "        individual (_type_): a valid GE individual\n",
    "        nf (_type_): numerical features\n",
    "        bf (_type_): boolean features\n",
    "\n",
    "    Raises:\n",
    "        GE_ExecuteError: if error happens during the execution of the individual\n",
    "\n",
    "    Returns:\n",
    "        int: 0 if the case is negative, 1 if the case is positive\n",
    "    \"\"\"\n",
    "    \n",
    "    nf = np.array(nf)\n",
    "    bf = np.array(bf)\n",
    "    \n",
    "    assert nf.ndim == bf.ndim, \"Numerical and Boolean data must have the same number of dimensions\"\n",
    "    \n",
    "    # execute\n",
    "    try:\n",
    "        if nf.ndim == 1:\n",
    "            res = eval(individual.phenotype)\n",
    "            pred = 1 if res > 0 else 0\n",
    "            return pred\n",
    "        \n",
    "        if nf.ndim == 2:\n",
    "            assert nf.shape[0] == bf.shape[0], \"Numerical and Boolean data must have the same number of samples\"\n",
    "            \n",
    "            nf = nf.T\n",
    "            bf = bf.T\n",
    "        \n",
    "            res = eval(individual.phenotype)\n",
    "            pred = [1 if res[i] > 0 else 0 for i in range(len(res))]\n",
    "            return pred\n",
    "        \n",
    "        raise NotImplementedError(\"Data with more than 2 dimensions is not supported\")\n",
    "        \n",
    "    except (\n",
    "        FloatingPointError,\n",
    "        ZeroDivisionError,\n",
    "        OverflowError,\n",
    "        MemoryError,\n",
    "        IndexError,\n",
    "        TypeError,\n",
    "    ) as e:\n",
    "        raise GE_ExecuteError(str(e))\n",
    "\n",
    "def fitness(individual, points):\n",
    "    if individual.invalid:\n",
    "        return np.nan,\n",
    "    \n",
    "    x, Y = points\n",
    "    \n",
    "    nf = x[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "    bf = x[BOOLEAN_FEATURES].to_numpy()\n",
    "    \n",
    "    try:\n",
    "        pred = gePredict(individual, nf, bf)\n",
    "        \n",
    "        errRate = np.sum(np.abs(Y - pred)) / len(Y)\n",
    "    except GE_ExecuteError:\n",
    "        return np.nan,\n",
    "\n",
    "    \n",
    "    return (errRate,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# define a single objective, minimising fitness strategy:\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", grape.Individual, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox.register(\"populationCreator\", grape.sensible_initialisation, creator.Individual)\n",
    "toolbox.register(\"evaluate\", fitness)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=7)\n",
    "toolbox.register(\"mate\", grape.crossover_onepoint)\n",
    "toolbox.register(\"mutate\", grape.mutation_int_flip_per_codon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "X_train = trainDf.drop(columns=[\"output\"])\n",
    "y_train = trainDf[\"output\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen = 0 , Best fitness = (0.29432764775882586,)\n",
      "gen = 1 , Best fitness = (0.29432764775882586,) , Number of invalids = 274\n",
      "gen = 2 , Best fitness = (0.29432764775882586,) , Number of invalids = 129\n",
      "gen = 3 , Best fitness = (0.29432764775882586,) , Number of invalids = 87\n",
      "gen = 4 , Best fitness = (0.29432764775882586,) , Number of invalids = 164\n",
      "gen = 5 , Best fitness = (0.29432764775882586,) , Number of invalids = 253\n",
      "gen = 6 , Best fitness = (0.29174930583101943,) , Number of invalids = 230\n",
      "gen = 7 , Best fitness = (0.29174930583101943,) , Number of invalids = 247\n",
      "gen = 8 , Best fitness = (0.2907576358587862,) , Number of invalids = 237\n",
      "gen = 9 , Best fitness = (0.2907576358587862,) , Number of invalids = 255\n",
      "gen = 10 , Best fitness = (0.2901626338754463,) , Number of invalids = 239\n",
      "gen = 11 , Best fitness = (0.2901626338754463,) , Number of invalids = 254\n",
      "gen = 12 , Best fitness = (0.2899642998809996,) , Number of invalids = 224\n",
      "gen = 13 , Best fitness = (0.2887742959143197,) , Number of invalids = 184\n",
      "gen = 14 , Best fitness = (0.2887742959143197,) , Number of invalids = 186\n",
      "gen = 15 , Best fitness = (0.2887742959143197,) , Number of invalids = 190\n",
      "gen = 16 , Best fitness = (0.27727092423641414,) , Number of invalids = 167\n",
      "gen = 17 , Best fitness = (0.27727092423641414,) , Number of invalids = 165\n",
      "gen = 18 , Best fitness = (0.27727092423641414,) , Number of invalids = 172\n",
      "gen = 19 , Best fitness = (0.27727092423641414,) , Number of invalids = 159\n",
      "gen = 20 , Best fitness = (0.2685442284807616,) , Number of invalids = 190\n",
      "gen = 21 , Best fitness = (0.2685442284807616,) , Number of invalids = 194\n",
      "gen = 22 , Best fitness = (0.26794922649742164,) , Number of invalids = 170\n",
      "gen = 23 , Best fitness = (0.2675525585085284,) , Number of invalids = 157\n",
      "gen = 24 , Best fitness = (0.26715589051963506,) , Number of invalids = 121\n",
      "gen = 25 , Best fitness = (0.26715589051963506,) , Number of invalids = 134\n",
      "gen = 26 , Best fitness = (0.2655692185640619,) , Number of invalids = 136\n",
      "gen = 27 , Best fitness = (0.2655692185640619,) , Number of invalids = 122\n",
      "gen = 28 , Best fitness = (0.2655692185640619,) , Number of invalids = 112\n",
      "gen = 29 , Best fitness = (0.2655692185640619,) , Number of invalids = 105\n",
      "gen = 30 , Best fitness = (0.2655692185640619,) , Number of invalids = 87\n",
      "gen = 31 , Best fitness = (0.2653708845696152,) , Number of invalids = 61\n",
      "gen = 32 , Best fitness = (0.2653708845696152,) , Number of invalids = 50\n",
      "gen = 33 , Best fitness = (0.2653708845696152,) , Number of invalids = 48\n",
      "gen = 34 , Best fitness = (0.26477588258627527,) , Number of invalids = 46\n",
      "gen = 35 , Best fitness = (0.26477588258627527,) , Number of invalids = 37\n",
      "gen = 36 , Best fitness = (0.26457754859182864,) , Number of invalids = 37\n",
      "gen = 37 , Best fitness = (0.26457754859182864,) , Number of invalids = 48\n",
      "gen = 38 , Best fitness = (0.26457754859182864,) , Number of invalids = 54\n",
      "gen = 39 , Best fitness = (0.2641808806029353,) , Number of invalids = 76\n",
      "gen = 40 , Best fitness = (0.2639825466084887,) , Number of invalids = 80\n",
      "gen = 41 , Best fitness = (0.26378421261404206,) , Number of invalids = 67\n",
      "gen = 42 , Best fitness = (0.26378421261404206,) , Number of invalids = 50\n",
      "gen = 43 , Best fitness = (0.2631892106307021,) , Number of invalids = 44\n",
      "gen = 44 , Best fitness = (0.26219754065846884,) , Number of invalids = 44\n",
      "gen = 45 , Best fitness = (0.2606108687028957,) , Number of invalids = 41\n",
      "gen = 46 , Best fitness = (0.2606108687028957,) , Number of invalids = 44\n",
      "gen = 47 , Best fitness = (0.2606108687028957,) , Number of invalids = 55\n",
      "gen = 48 , Best fitness = (0.2606108687028957,) , Number of invalids = 38\n",
      "gen = 49 , Best fitness = (0.2606108687028957,) , Number of invalids = 22\n",
      "gen = 50 , Best fitness = (0.2606108687028957,) , Number of invalids = 25\n",
      "gen = 51 , Best fitness = (0.2596191987306624,) , Number of invalids = 33\n",
      "gen = 52 , Best fitness = (0.2594208647362158,) , Number of invalids = 25\n",
      "gen = 53 , Best fitness = (0.2594208647362158,) , Number of invalids = 21\n",
      "gen = 54 , Best fitness = (0.25922253074176915,) , Number of invalids = 38\n",
      "gen = 55 , Best fitness = (0.25922253074176915,) , Number of invalids = 35\n",
      "gen = 56 , Best fitness = (0.25882586275287583,) , Number of invalids = 22\n",
      "gen = 57 , Best fitness = (0.25882586275287583,) , Number of invalids = 15\n",
      "gen = 58 , Best fitness = (0.2584291947639826,) , Number of invalids = 12\n",
      "gen = 59 , Best fitness = (0.2582308607695359,) , Number of invalids = 11\n",
      "gen = 60 , Best fitness = (0.2582308607695359,) , Number of invalids = 9\n",
      "gen = 61 , Best fitness = (0.25803252677508925,) , Number of invalids = 9\n",
      "gen = 62 , Best fitness = (0.25763585878619594,) , Number of invalids = 6\n",
      "gen = 63 , Best fitness = (0.25763585878619594,) , Number of invalids = 8\n",
      "gen = 64 , Best fitness = (0.25684252280840936,) , Number of invalids = 5\n",
      "gen = 65 , Best fitness = (0.25684252280840936,) , Number of invalids = 5\n",
      "gen = 66 , Best fitness = (0.25684252280840936,) , Number of invalids = 10\n",
      "gen = 67 , Best fitness = (0.25684252280840936,) , Number of invalids = 4\n",
      "gen = 68 , Best fitness = (0.25644585481951604,) , Number of invalids = 16\n",
      "gen = 69 , Best fitness = (0.25644585481951604,) , Number of invalids = 21\n",
      "gen = 70 , Best fitness = (0.25644585481951604,) , Number of invalids = 13\n",
      "gen = 71 , Best fitness = (0.25644585481951604,) , Number of invalids = 21\n",
      "gen = 72 , Best fitness = (0.25644585481951604,) , Number of invalids = 24\n",
      "gen = 73 , Best fitness = (0.25585085283617615,) , Number of invalids = 38\n",
      "gen = 74 , Best fitness = (0.25585085283617615,) , Number of invalids = 35\n",
      "gen = 75 , Best fitness = (0.25585085283617615,) , Number of invalids = 40\n",
      "gen = 76 , Best fitness = (0.25585085283617615,) , Number of invalids = 58\n",
      "gen = 77 , Best fitness = (0.25585085283617615,) , Number of invalids = 99\n",
      "gen = 78 , Best fitness = (0.25585085283617615,) , Number of invalids = 81\n",
      "gen = 79 , Best fitness = (0.25585085283617615,) , Number of invalids = 90\n",
      "gen = 80 , Best fitness = (0.25585085283617615,) , Number of invalids = 106\n",
      "gen = 81 , Best fitness = (0.25585085283617615,) , Number of invalids = 77\n",
      "gen = 82 , Best fitness = (0.25565251884172946,) , Number of invalids = 109\n",
      "gen = 83 , Best fitness = (0.25565251884172946,) , Number of invalids = 80\n",
      "gen = 84 , Best fitness = (0.25565251884172946,) , Number of invalids = 76\n",
      "gen = 85 , Best fitness = (0.25565251884172946,) , Number of invalids = 94\n",
      "gen = 86 , Best fitness = (0.25565251884172946,) , Number of invalids = 88\n",
      "gen = 87 , Best fitness = (0.25565251884172946,) , Number of invalids = 76\n",
      "gen = 88 , Best fitness = (0.25446251487504956,) , Number of invalids = 93\n",
      "gen = 89 , Best fitness = (0.25446251487504956,) , Number of invalids = 99\n",
      "gen = 90 , Best fitness = (0.25446251487504956,) , Number of invalids = 113\n",
      "gen = 91 , Best fitness = (0.25446251487504956,) , Number of invalids = 73\n",
      "gen = 92 , Best fitness = (0.25446251487504956,) , Number of invalids = 73\n",
      "gen = 93 , Best fitness = (0.25446251487504956,) , Number of invalids = 60\n",
      "gen = 94 , Best fitness = (0.25446251487504956,) , Number of invalids = 72\n",
      "gen = 95 , Best fitness = (0.25446251487504956,) , Number of invalids = 70\n",
      "gen = 96 , Best fitness = (0.25446251487504956,) , Number of invalids = 79\n",
      "gen = 97 , Best fitness = (0.25446251487504956,) , Number of invalids = 57\n",
      "gen = 98 , Best fitness = (0.25446251487504956,) , Number of invalids = 62\n",
      "gen = 99 , Best fitness = (0.25446251487504956,) , Number of invalids = 56\n",
      "gen = 100 , Best fitness = (0.2538675128917096,) , Number of invalids = 52\n"
     ]
    }
   ],
   "source": [
    "# population and hall of fame:\n",
    "population = toolbox.populationCreator(\n",
    "    pop_size=POPULATION_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    min_init_depth=MIN_INIT_TREE_DEPTH,\n",
    "    max_init_depth=MAX_INIT_TREE_DEPTH,\n",
    "    codon_size=CODON_SIZE,\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    ")\n",
    "hof = tools.HallOfFame(HALLOFFAME_SIZE)\n",
    "\n",
    "# prepare the statistics object:\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.nanmean)\n",
    "stats.register(\"std\", np.nanstd)\n",
    "stats.register(\"min\", np.nanmin)\n",
    "stats.register(\"max\", np.nanmax)\n",
    "\n",
    "# run the algorithm:\n",
    "population, logbook = ge_eaSimpleWithElitism(\n",
    "    population,\n",
    "    toolbox,\n",
    "    cxpb=P_CROSSOVER,\n",
    "    mutpb=P_MUTATION,\n",
    "    ngen=MAX_GENERATIONS,\n",
    "    elite_size=ELITE_SIZE,\n",
    "    bnf_grammar=grammar,\n",
    "    codon_size=CODON_SIZE,\n",
    "    max_tree_depth=MAX_TREE_DEPTH,\n",
    "    max_genome_length=MAX_GENOME_LENGTH,\n",
    "    points_train=[X_train, y_train],\n",
    "    # points_test=[X_test, y_test],\n",
    "    codon_consumption=CODON_CONSUMPTION,\n",
    "    report_items=REPORT_ITEMS,\n",
    "    genome_representation=GENOME_REPRESENTATION,\n",
    "    stats=stats,\n",
    "    halloffame=hof,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7205cf934940>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "gen = logbook.select(\"gen\")\n",
    "fit_mins = logbook.select(\"min\")\n",
    "fit_avgs = logbook.select(\"avg\")\n",
    "\n",
    "plt.plot(gen, fit_mins, \"b-\", label=\"Minimum Fitness\")\n",
    "plt.plot(gen, fit_avgs, \"r-\", label=\"Average Fitness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual: \n",
      " or_(and_(greater_than(nf[0], sub(add(sub(mul(0.9807, 0.2344), div(nf[2],\n",
      "div(4.0982, 8.5549))), div(nf[1], sub(nf[1], mul(mul(sub(nf[4], nf[3]),\n",
      "-0.6948), nf[3])))), nf[2])), or_(not_(not_(not_(not_(and_(not_(bf[1]),\n",
      "and_(not_(bf[11]), bf[5])))))), and_(bf[2], or_(and_(not_(bf[11]), bf[5]),\n",
      "and_(bf[1], bf[0]))))), and_(or_(or_(not_(not_(not_(not_(and_(and_(bf[11],\n",
      "bf[5]), and_(not_(or_(bf[0], not_(and_(not_(bf[8]), not_(or_(bf[1],\n",
      "greater_than(mul(-3.2961, mul(div(add(nf[3], nf[2]), nf[2]), add(nf[6],\n",
      "add(nf[2], 2.8552)))), nf[6]))))))), not_(bf[8]))))))), and_(bf[5],\n",
      "and_(or_(or_(bf[0], not_(less_than(-4.1190, div(add(nf[3], -9.5426), 5.5295)))),\n",
      "not_(bf[8])), and_(or_(bf[1], greater_than(mul(sub(nf[4], nf[3]), -0.6943),\n",
      "nf[3])), and_(or_(or_(not_(not_(not_(not_(and_(not_(bf[1]), and_(not_(bf[11]),\n",
      "bf[5])))))), not_(bf[2])), or_(and_(not_(bf[11]), bf[5]), and_(bf[1], bf[0]))),\n",
      "not_(greater_than(sub(3.3299, mul(mul(nf[1], nf[4]), 0.2244)), sub(nf[2],\n",
      "div(-9.0642, sub(nf[4], nf[3])))))))))), not_(bf[8])), and_(bf[0],\n",
      "not_(not_(or_(and_(or_(or_(bf[5], and_(bf[1], and_(greater_than(9.5529,\n",
      "div(nf[1], sub(nf[1], 0.2997))), or_(bf[8], bf[3])))), bf[8]),\n",
      "not_(or_(and_(and_(bf[0], bf[4]), not_(less_than(-0.3906, 8.8712))),\n",
      "or_(not_(not_(not_(not_(and_(not_(bf[1]), and_(not_(bf[11]),\n",
      "or_(greater_than(2.1395, -6.9746),\n",
      "and_(or_(or_(not_(not_(not_(not_(and_(and_(bf[11], or_(bf[10], and_(bf[8],\n",
      "not_(bf[0])))), greater_than(sub(3.3831, sub(nf[6], sub(nf[2], nf[2]))),\n",
      "2.5397)))))), or_(greater_than(mul(6.3695, sub(nf[3], -0.2648)), sub(-5.3406,\n",
      "nf[3])), bf[2])), or_(bf[4], not_(less_than(-0.3906, -5.8712)))),\n",
      "or_(not_(not_(not_(not_(and_(not_(bf[1]), and_(not_(bf[11]), bf[5])))))),\n",
      "and_(bf[2], or_(and_(not_(bf[11]), bf[5]), and_(bf[1], bf[0])))))))))))),\n",
      "and_(greater_than(nf[3], nf[2]), and_(bf[6], and_(bf[5],\n",
      "and_(not_(and_(or_(bf[0], or_(or_(bf[10], and_(or_(and_(bf[3],\n",
      "not_(not_(bf[10]))), less_than(mul(8.5529, div(nf[3], sub(nf[1], nf[6]))),\n",
      "sub(-5.3406, nf[6]))), bf[2])), or_(or_(or_(not_(less_than(-0.3906, 8.8782)),\n",
      "or_(not_(not_(not_(not_(and_(not_(bf[10]), and_(not_(bf[11]), bf[5])))))),\n",
      "and_(bf[2], or_(and_(not_(bf[11]), bf[5]), and_(bf[1],\n",
      "or_(and_(not_(greater_than(2.8997, div(-8.0164, nf[0]))),\n",
      "greater_than(div(nf[0], nf[5]), 0.5563)), or_(and_(not_(bf[11]), bf[5]),\n",
      "and_(bf[2], or_(and_(not_(bf[11]), bf[5]), and_(bf[1], bf[0])))))))))),\n",
      "and_(or_(or_(not_(not_(not_(not_(and_(not_(bf[11]), bf[5]))))),\n",
      "and_(not_(or_(bf[0], not_(less_than(5.7930, nf[5])))), or_(bf[11],\n",
      "greater_than(nf[1], -5.6958)))),\n",
      "not_(or_(and_(or_(not_(not_(not_(not_(not_(or_(not_(bf[11]), not_(or_(bf[3],\n",
      "or_(greater_than(nf[0], mul(9.5529, div(nf[1], sub(nf[1], mul(mul(sub(nf[4],\n",
      "nf[1]), 0.5547), div(nf[1], sub(nf[1], mul(mul(sub(nf[4], nf[3]), -9.7948),\n",
      "nf[3])))))))), and_(or_(or_(not_(not_(not_(and_(and_(not_(bf[1]),\n",
      "and_(not_(bf[11]), bf[5])), and_(bf[2], or_(and_(not_(bf[11]), bf[5]),\n",
      "and_(bf[1], bf[0]))))))), and_(or_(less_than(add(-6.2545, nf[6]), nf[2]),\n",
      "not_(not_(and_(not_(bf[8]), not_(or_(bf[1], less_than(-5.3406, nf[1]))))))),\n",
      "and_(not_(bf[11]), bf[5]))), and_(bf[1], bf[0])), and_(bf[8],\n",
      "not_(not_(not_(not_(and_(and_(bf[11], bf[5]), less_than(sub(add(mul(nf[3],\n",
      "sub(nf[2], div(4.0922, 8.5746))), nf[2]), nf[0]), add(-6.4545,\n",
      "nf[6])))))))))))))))))), or_(bf[0], not_(and_(not_(bf[8]), or_(or_(bf[1],\n",
      "greater_than(nf[4], -3.2961)), bf[8]))))), or_(bf[3],\n",
      "not_(not_(not_(not_(or_(or_(not_(not_(not_(or_(and_(not_(bf[11]),\n",
      "greater_than(mul(sub(nf[4], sub(-0.6751, nf[1])), nf[3]), -3.4741)), and_(bf[8],\n",
      "and_(bf[3], not_(not_(or_(bf[9], bf[11]))))))))), bf[4]), and_(bf[6],\n",
      "less_than(-1.3906, -1.2746))))))))), or_(less_than(-2.2338, -6.4545),\n",
      "and_(not_(or_(bf[0], not_(less_than(mul(-9.5024, 5.5291), 2.3383)))),\n",
      "and_(not_(bf[11]), bf[5])))))), and_(bf[1], bf[0]))), not_(less_than(-9.5161,\n",
      "5.9291))))), not_(bf[8]))), and_(bf[0],\n",
      "not_(not_(or_(and_(or_(not_(not_(not_(not_(not_(and_(bf[9], greater_than(nf[2],\n",
      "-4.6803))))))), bf[1]), bf[2]), and_(and_(and_(bf[3],\n",
      "not_(not_(and_(not_(bf[1]), bf[5])))), and_(bf[1], bf[0])),\n",
      "not_(less_than(-4.6053, -3.2148))))))))))))))), and_(bf[11], less_than(9.7165,\n",
      "add(nf[2], 3.1797)))))))))\n",
      "\n",
      "Training Fitness:  0.2538675128917096\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "best = hof.items[0].phenotype\n",
    "print(\"Best individual: \\n\", \"\\n\".join(textwrap.wrap(best, 80)))\n",
    "print(\"\\nTraining Fitness: \", hof.items[0].fitness.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hof.items[0].phenotype, file=open(\"best_individual.txt\", \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data \n",
    "testDf = pd.read_csv('test.csv')\n",
    "testDf[CONTINUOUS_FEATURES] = stdScaler.transform(testDf[CONTINUOUS_FEATURES])\n",
    "testDf[ORDINAL_FEATURES] = minMaxScaler.transform(testDf[ORDINAL_FEATURES])\n",
    "\n",
    "X_test = testDf\n",
    "\n",
    "res = []\n",
    "\n",
    "for i, row in X_test.iterrows():\n",
    "    nf = row[CONTINUOUS_FEATURES + ORDINAL_FEATURES].to_numpy()\n",
    "    bf = row[BOOLEAN_FEATURES].to_numpy()\n",
    "\n",
    "    pred = gePredict(hof.items[0], nf, bf)\n",
    "    res.append(pred)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df of index, output; index [0...n-1]; output is above\n",
    "\n",
    "outputDf = pd.DataFrame(res, columns=[\"output\"])\n",
    "outputDf[\"index\"] = outputDf.index\n",
    "\n",
    "outputDf = outputDf[[\"index\", \"output\"]]\n",
    "\n",
    "outputDf.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
